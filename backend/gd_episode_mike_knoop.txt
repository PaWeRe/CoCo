you're listening to gradient descent a show about making machine learning work in the real world and I'm your host leas spal this is a conversation with Mike Knoop who is both an AI researcher and an incredibly successful entrepreneur he started a company called zapier about 15 years ago with a very small amount of funding and grew it into a very large business he then got up to speed on the frontier of AI research and recently started an organization called India which is one of the new research Labs working on the Forefront of AI this is a really interesting conversation we go into business and how AI fits into business and then also some of the details on how the new R1 and r10 models work especially on the AGI prize which he funded and made popular I really hope you enjoy this [Music] conversation why don't we start with uh with R1 and work work backwards um so sounds good let's let's do it so so um R1 obviously this um suddenly famous model um coming out of China do you want to maybe just describe that briefly and then talk about um R1 Z as well and and yeah picate a little bit so um yeah the these uh these basically two actual models got dropped r10 and R1 they are very similar in sort of nature to um what I would call open as01 model they're you know these reasoning models and they were trained in a a similar way we we know for sure how R1 and r10 train Because deep seek chose to open source their sort of uh sort of training methodology um for for R1 r10 they really did move the science forward here I did see a public comment from I think Mark Chen who leads research at opena on this stuff that um you know he he shared that like he thinks that you similar in spirit to how Owen was trained as well so I think there's some pretty good agreement here between sort of the ideas that have gone into Crea both of these both of these systems and fundamentally the whole like the O Series from open AI this like R series from um from Deep seek are fundamentally a paradigm shift from the type of AI systems that we've seen in the past uh for example from open AI like GPT series you know from three to three and a half to four to 40 these are all the same sort of like broad Paradigm of scaling up pre-training where we're trying to make the sort of models more intelligent by feeding them you know more data making the models bigger now it is also the case if for was actually a little likely smaller you know there there's probably some distillation that went need four to make it more efficient but but roughly we're sort of in the broad Paradigm of making models smarter by trying to like give them more human data um and they're effectively memorizing answers this means that they really have no ability to adapt to novelty um May Hur of you know the arc Arc prize The Arc AGI Benchmark what this is is if the benchmark that tries to assert or assess a AI system's ability to solve problems that it hasn't seen before uh the data that's highly resistant to just like being able to memorize the answers even if you're given the training set for Arc it's you can't just memorize the training set and solve the test Set uh this is kind of another underappreciated sort of public Point um legit legitimately is very hard that's why it went unbeaten V1 went unbeaten for for sort of 5 years and um you know in December we had this big news moment with the open aos3 you know they had the 75% score on um on on rv1 they had this 85% score with this really you know expensive High compute performance version of it and this was showing that this kind of like new reasonings type of system is um has a fundamental new capability we've not had in computers before that they have the ability to adapt to to novelty and this actually has some implications in you know beyond just that quirky F fact this will actually lead to more sort of robust and reliable AI systems too which we can we can touch on it matters a lot for this agent stuff um wait before we before we go down that path they like immediately off track and I I love it but you know when you talk about like novelty like you know how do you define that right because I feel like there's a lot of debate on like are these systems just memorizing or not and they're obviously not just like memorizing text and then like regurgitating exactly the same text I mean it's quite clear there's like some you know adaptation um so yeah there's some of generalization that comes from like compression right because like it's literally it's not literally a database which would be like a lookup table right exactly you know if you had one parameter for every fact okay you could just have a database you know these these the these like GPD style class systems do do compression that is where you get some of the like interesting generalization coming from the sort of claim that I would have is that the amount of generalization they're capable of doing is fixed because the architecture is fixed effectively you've got the Transformer underlying architecture in every languish model up until you know last year um and that means that your sort of level of intelligence is fixed yeah you can memorize more but the amount of generalization you have the amount of adaptability you can do from your training data to a new Nevel situation it has been fixed and that has not changed up until 01 01 was the first prototype we saw last September of a system that actually had a legitimately increased amount of intelligence in its ability to be given a fixed amount of input information be able to do more things accurately uh they're further away from its training data but wait so like what would you would you say that like for example Alpha go couldn't generalize like it seems like in the domain of go it could reason pretty well and adapt to to novel situations no true for Arc to right I mean arc's been around for five years there's a lot of uh you know state of the arc and Arc from a pure solver standpoint if you sort of disregard the you know front end LMS was like something like um 50% coming out of the arc price 2024 contest but they're very very domain specific solvers uh you know they required researchers to have a uh they basically um you know these systems have all of their G the G Factor the generality is being put into the sort of system that solved Arc in the during the contest uh that came from the researcher's brain right because the researcher thinking about the problem they're trying to model the problem and say okay here's what I'm trying to get this computer to do I'm G to like encode my own understanding of the problem into the system into the architecture in order to get this thing to work and it ends up being fairly sort of you know constrained in domain um and it doesn't generalize well and this is true for alago too you know we've had AI systems for years and years and years that can be be super humid that at hum of games um but like the fact has s historically remained that you know uh what what can you do that these AI systems can't it it's the fact that I could like sit you down look this and teach you a new card game new board game in like a couple hours and get you up to human level proficiency you know I could Takei you in a to totally new day I could go teach you how to drive a car you've never driven before and get you up your proficiency probably in a couple days uh this like ability to adapt on the fly to a situation or type of problem that you've never seen before but never trained on is what has been historically very unique and special to you as like a human relative to the AI systems that we have today and it's probably worth saying like I don't know how you Arc is I think better looked at than described in words but we like overlay like a puzzle somewhere here totally yeah it's over it's for sure to Overlay a puzzle but um you know for someone just like listening you know I think what's astonishing about Arc is maybe how easy these puzzles seem to be and how um these systems do actually fail on these easy looking puzzles but maybe you could describe a little bit more of of yeah what it is it looks like an IQ test it's a grid of colors it's a you know 2D grid of colors we were given some examples of input and outputs and your goal is to find the the rule to find the pattern between what's the common consistent rule between these inputs and outputs and then apply it on a test that you're given um and uh and yeah you're right it's easier to sort of visually describe or visually then sort of describe um but you know arcs basically challenges you to uh like on the Fly recompose knowledge that you've acquired throughout your life basically on what we call these like core knowledge priors um these are things like Symmetry and rotation and object detection and tracking and basic understandings of physics um Arc requires you to kind of abstract and compose those core knowledge prior on the fly to a task that you've never seen before and uh this is what the sort of historical LM scaling appar I was never even good at it like gb4 scored 40 scored like 4% for example on the arc data set in contrast to the really impressive performance we started to see from these o systems okay so what changed in from like 40 to these o systems that are doing well like what what do they do differently to to make it work better yeah I mean fundamentally like the the strongest thing I can say is from a capability I can make a very strong capability assertion and then I can have some informed speculation on how uh you know the capability assertion you see this in um just the score if you look at arv1 right uh for over a 5year period from when it was first introduced in 2019 up through basically last fall the best sort of LM gp4 got 4% on it um and then 01 came out o1 Pro came out O3 came out and you saw the score rapidly go from 4% all the way up to 75 85% on this really extreme high-end performance version of of O3 it looks like a a straight line like it's pretty pretty nuts and this is actually a really good thing to see in a benchmark actually um this means there's more signal in the benchmark it truly is doing a capability assertion you know it's a little tougher to understand capabilities by looking at these like kind of monotonically smoothly increasing benchmark scores that go slowly over time um when you see something have a sharp Bend you know that something has distinctly changed and I think that's the case with these these these reasoning systems and specifically the thing that they have done is they have added the ability to recompose knowledge that they've been trained on in their Foundation models at test time openi calls this like test time compute this kind of the broad Paradigm if we want to use more test time to uh we want to use more compute at test time to like think before we just jump to an answer you know gb4 you starts spitting out tokens in 500 milliseconds and you know that's its answer whereas you know the intuition here is we want allow these systems to have more time thinking up front before they have to render render a view and the way they think is by what's called this like Chain of Thought parano um you might have heard like let's think step by step right this like cromac that came out literally like three years ago this this paper actually is very special to me was one of the things that got me first into go all in on AI um but this like Co moment that happened in literally January 2022 like we're just s like Downstream of of that moment still we're trying to figure out how can we apply this Paradigm of Chain of Thought about having the models basically think out loud to themsel in a sequence where you say okay hey what's the next step to solve this problem okay now take that next step what's the next step Okay now what's the next step and you do this sort of in a big a big in a in a big chain and then the model's able to use that entire sort of a fought trajectory to grounded Final Answer um and this is what o1 does this is what R1 does this is what r10 does um there there is some differences between R1 Z and R1 we should talk about that are very important but roughly before we go there maybe let's take a moment to be like astonished that this works right because you're saying that these like llms are compression algorithms that you know kind of can't reason they can only sort of you know do some kind of like limited um you know generalization they're now like generating text and the Chain of Thought you know paper had them generating text in steps so so these these kind of dumb models are generating text now in steps and suddenly you claim they can reason like that that doesn't seem obvious that that would um I don't think it is it's one of the reasons why I like I said I went all in on AI back in 2022 uh there was this like up until January 2022 and I could found a zapier 15 years ago but working on it I was an ex act at the time was like running all of our product engineering org like half the company building our new product stuff and I saw this and I I've been paying attention to Ai and I saw this Chain of Thought paper that came out and I I thought I had a good perspective of like what LMS could do and couldn't do up to that point and and then this paper drop was like oh just by asking them all think out loud you saw these performance scores on the reasoning benchmarks at the time were showing really really uh large spiking behavior and they grow from 30% to like 70% or so and that was like my my kind of like oh shoot moment are we on track for AGI with this technology possibly um and I felt that was really important to know first just from a zappier standpoint like should we start using this in our products and and also you know just from Human I just want to know this is really I think this is some of the most important technology in history of the world and so I kind of went all ending start understanding the sort of Paradigm here one interesting thing about that old school version of Chain of Thought like we zapper was like proud typing which Chain of Thought in Fall 2022 as well with a very similar Paradigm of like ask model to L propped it out loud it has a it has a very low degree of ability to adapt and and we see this even with 01 and R1 you know the scores on Arc are only about 15% it is a big step up from the sort of GPD 40 class you know the 5% territory but it's still really it's a relatively weak amount of adaptation that the thing that has really made these things work with 01 Pro and and NO3 and this is getting an informed speculation is they've added search and sampling on top of the co generation proc process they're not just asking for a single Co and then say okay now give me the answer they are sort of generating multiple coot steps in parallel and saying okay which one's the best one okay use that one now go to the next step now ask me for a bunch more pick the best one go to the next one they're effectively doing this like program synthesis or program search at inference time and this this insight has allowed a significantly higher degree of like adaptation is what's getting up to the 75 85% and I I'll be like you know to your original point this is astonishing like it's a big update I think these these systems demand like serious study uh and it's also why I'm very excited to see R1 and R1 Z open source because I think that's gonna allow more people to do the science totally and before we get into the R1 and and r10 what like what's the human uh performance on Arc and and where where are these best models at today like when you say 85% put that in context of of human level performance uh humans like smart humans can get up basically 100% on rp1 I see yeah if if you like the data we have is like if you take two like what's called stem graduate humans and put them in front they'll get 100% like I think the actual data we have is like 98 99% across two this has been one of the actual flaws of V1 is that we haven't had like strong assertions of human capability something we're fixing at V2 we've actually been work on V2 for years now actually we put a lot of effort into building it last summer and um we're putting the final Tes on it right now and we're going to laun it with ar price 2025 this year one of the things we have with V2 is actually strong uh human study Baseline testing to make confident assertions that every single puzzle in The Benchmark is solvable by humans in order to justify the easy for human CL I do think that that is the spiritual guidance of like the arc Benchmark in the future is I it's this is true for V1 will be for v2 and V3 and all future versions is that we want Arc to represent this concept of things that are easy for humans and hard for AI and I think that's the gradient we're driving to zero because I think if you could get that Gap to zero you you legitimately I think it's going to be hard for anyone to claim we don't have ai if there's no if you can't find a single thing that like humans find easy but humans find computers find hard you know I think that's a reasonable like goal to set and a Target to shoot for and this isn't this is in contrast to like how a lot of other Frontier benchmarks work you know Dan Hendrick's like humity last exam or epic AI Frontier math they're investing in making like these ever more difficult benchmarks and and I think that's a fine thing to do by the way I don't sort of discount that effort at all I think it's useful but I think there's something more important to understand from a capability assertion standpoint around like well what what do humans still find easy I think that's more revealing of something we're missing in these system still I totally agree although it's it's funny I mean it's been such a long line in my lifetime and especially in the last year or two of like you know these benchmarks just being like okay this is human level performance if we get there we're going to have AGI and then like over and over and over and over um you know beating these benchmarks like do you I guess it's really hard to make this claim with certainty but do you feel like Arc could be like the last um of this genre like is there something else out there that that um you know AI solves this but then there's something left as a benchmark that it can't do that humans can do easily what I can say more confidently is that we're going to run the gap of easy for humans hard for at a zero you know I think that is a up to the world to decide is that egi I personally think it is um but that that is our that's the design philosophy we have for for v2 that's going to be the design Philosophy for V3 in future versions I'll say this like you know V2 is going to look probably pretty similar to V1 in terms of domain because we've been working on it forever um it is harder for computers but it's still easy for AI um V3 will likely be something that looks very different from what we've done so far I think it will look like Arc still but like I think it's going to test different capabilities that humans still find quite quite easy um that the sort current benchmarks don't and likely also include a sort of formal version of measuring efficiency which I think is also going to be a really important thing we care about getting up to AI okay so so R1 and r10 can I mean can you describe what those are and how how they do like why they do well on on Arc so r10 R1 both kind of in the spirit of being trained on coot chains of thought and then generating them um basically a single coot and then you know giving us an answer I think the really important thing to know about is how what differs why is R why why are there two models why is R1 Z and R1 different separate this is a very interesting thing like they didn't have to release r10 um in my view r10 is a more important system to understand R1 um as for this reason what does the zero stand for the zero stands for no human data in the training lert for like Alpha zero I guess is omage to that probably right yeah they're using it they're training it purely on RL reinforcement learning they're using domains and math and coding to create verifiers where they can have the model deep seek V3 generate a CO and then they can use a formal domain of like literally just run a computer program and feedback was that right or R but just to be clear justar before we go down that path so they're not obviously there's like a an earlier training step where there is human data in it right I mean they can't I mean how does it learn Lang there's a there's a foundation M uh deep seek 33 this is not a forever given though um I I think this is going to be an engineering try off that AI system developers have to make in the future which is how much knowledge do we put in the foundation model that we start from and how much do we have the system sort of you know generate itself at at like test time basically runtime um I think likely what you'll sort of my sort of expectation is you're going to use these reasoning style systems basically to generate new knowledge and add them back into s some like ever growing Corpus of knowledge that they have and you'll probably use those as your starting points in future training runs and future inference systems that you get um so yes it's it's it is the case obviously for was trained on human data steep seek V3 was trained on human data um but this is not going to be likely the forever case in terms of the capabilities of these systems I I I think you will see and this is why r10 is important to look at if if if it's able to bootstrap itself up in Knowledge from literally first principles like math you know give me the piano arithmetic operators and I'm going to bootstrap up Cal 3 like that is something legitimately that a system like r10 could potentially do using RL with no humans in BL okay so they train the system on they train like a foundation model on human data and then what's this next step that that they're doing with R1 zero just like specifically so they're they're generating chains of thought and then yeah yeah it's generating single chain of thought you know step by step taking the full Chain of Thought and then that whole thing is being used to get the final grounding for a final response out from the same deep SE fre through model and and how does the feedack get Incorporated done offline a training time um so what I just described is kind of like a test time right they didn't for how they work right it's like okay user inputs query I'm G to like generate one coot very long and give you a final answer but you know it's going to go forward uh the the feedback loops at um at training time this happens offline right the developers did this months ago uh you know where they took the DC V3 model and had it gener lots of Co and they had another computer programming looking at all those Cs and giving the sort of training Loop feedback like was that a good thought or a bad thought um and that that RL signal is basically being used to sort of fine-tune um the ultimate R1 zero model and then in the C of R1 full they they actually also allow human experts to label those as in the case of the zero how do they how do they have the original how do they have the model that knows if it's a good thought or a bad thought like how do you C start this is what's different from Zer vers1 so o1 uses a greater model um where they have where they have like a neural model basically giving feedback and saying like in text form oh good job bad job kind of like style stuff um R1 don't do this it's purely a symbolic verifier right so they they are like saying I'm going to run a I'm going to take this like you know potential code that you've just outputed try to symbolically run it and use it give a feedback signal and like is it good or bad and that's that's is that's generally what you're seeing in like this RL space right is like you want to get a sort of Final Answer uh and then you're gonna symbolically try to verify that and make a like a 100% a reliable assertion of whe whether that was right or wrong which is you can do it in domains where you can run a computer program to verify you know a Python program a math equation a piece of code does it does the code compile does it get the answer I expect you you've got benchmarks we we have all this stuff set um this is different from yeah some of the1 stuff where they're actually using a process grader model which is another a separately neural trained one we again this is all in form speculation I they haven't shared any of this so this is all like details I'm just like trying to pick up and understand based on these systems but that's that's what I understand is they have a they have a separate actual LM model that's getting Fe back in the training train load so the in the case of r10 it's it's pretty cool they've been so transparent about how they do it um do like is it possible that there's domains like computer programs that are really easy to do kind of Chain of Thought and then verify but then other domains where it's harder and so you end up with m s of specializing towards the domains where it's sort of easier to tell if if the result is accurate or not this is the bet right like can r10 scale up without having to add humans in the loop the the the evidence we have is that 03 which does way better on Arc like basically effectively beats the V1 data set um required supervised fine tuning from humans to get that to work at a high degree of a high enough degree of efficiency to make it like tractable uh we don't have any evidence yet that you can bootstrap a pure RL based LM Chain of Thought system to get there that's like what you're probably going to see happen though in 2025 I would expect I mean I think another obvious thing that that's you know come up with these models that people have noticed is that they were a lot cheaper to train by Yeah by orders of magnitude um why do you have a thought of why that is yeah I haven't look deeply into this um you know the the only commentary I probably can offer here that's interesting is you know the the the the ticket price is what people often are comparing here between like what's the what's the commercial pricing rate of like 01 versus what the deep seek commercial rate is for their model their hosting and you know because or when R ones you're open you can actually run them on your local infrastructure you don't have to go pay the rate like they're giving you basically an at cost like it's very close to the actual at cost and openi got margin they're company they got they got researchers to feed they got future research to invest in like you know they're building a business there so like my again informed speculation is that like there is a quite a bit of margin built into Owen's inference costs right now in order to fund future R&D and that the true costs are probably more comparable than most people expect uh at least for R1 and r10 vers1 uh I think there's this other debate of like how much did deep seek V3 cost to train you know are we hiding the fact that like this headline number oh it cost by million dollars to train R1 r10 Fus skates the fact that there was like a bunch of money that went into training the foundation model that that is accurate I have no idea how much the foundation M trained I haven't looked into this I have no sense of what it cost I don't I don't know what a gb4 CO cost either um but I but I but I would maybe make this the single comment on like from an inference cost uh I would sort of broadly put these like our our systems and O systems in some somewhat of the same Bucket from a cost basis like broadly speaking got it okay all right well thanks for jumping in I feel like maybe we should take a step backwards I think you know when I I first met you was like maybe more than a decade ago um you know you're the founder of a company called zapier which I've long admired but maybe some people have have not heard of you want to talk about what zapier does yeah zapier is an automation company uh we try to deliver um automation software that's very easy to use for non-technical folks in order to automate uh you know largely parts of their business um were used predominantly by um you know individual people either you know their own life on small teams um you know individual teams within large organizations this is very much easy it's tended to be very very easy to and that's in contrast with like historically uh you know the sort of automation system that that has existed out there we're used today by I think several I don't know three four million businesses in the US um you know we have a pretty large International presence as well from a customer based standpoint and you know the core idea is you can connect apps use um so you know you've got business software USS like Gmail or slack or Salesforce or uh G or whatever um and uh you know businesses build internal workflows around these process they often have humans that have to like shepher data between the different make decisions um and this is something zap can completely automate for you uh and it's easy enough to use for you know line of business type of folks that you don't have to get an engineer involved and I think some of the notable things about zap also is I mean this might be unique I mean you raised a tiny amount of money from VCS and then you got off the VC train like no almost nobody does and got to like incredible scale um I mean that's been an amazing return for your um initial investors and I think you're one of the first even raising the money in the first place um what's that we debated even running raising the money in first place you know we we um it kind of it was a very practical decision frankly to sort of Do It um you know the three founders me and Brian Wade you know we're all from Midwest I grew up in St Louis and you know there's no Venture Capital Market in the in the midwest really uh maybe they say a little bit but like you know 2010 nothing um and so how do you build the business like what you like build a useful service product you sell it you use the proceeds to invest back into the business and so that was kind of our bi um and how we kind of initially operated and you know we went through YC and you know we we're really debating should we you know we've got this demo day moment everyone else is gonna raise money should we and and you know we did office hours um actually funny up with like Sam mman uh who was the guy who we chatt out with they were like you know should should we raise or not and you know I think the question he asked us was like well look what you know what are your what's the constraint of the business and it was a good question because I think you know the legit constraint on the business for for zpp here at the time was Brian way and I were all waking up and doing support and like noon every day and so it was taking away time to make the product better to not have as much support in the first place and we're like oh well we should go hire a support person and we didn't have enough cash you know on hand yet to go hire that person so we decided to go you know raise raise a small round in order to like you know um be able to hire someone ASAP to like you know give us more product in time back and the funny anecdote sad anecdote is that by time we like got the round raised got the money in the bank found the person who hire got them on board started payroll and they had their first paycheck Revenue had actually caught up enough to just pay them directly and so I'm pretty sure you could like trace the million dollars that we raised like in lineage all the way through like to today which you know it did it did allow us to like activate though and start which I think is honestly the biggest value we got out of YC which was just like the activation moment to like really go on and get and go full-time on it amazing and you were also remote first from the beginning right yeah another another weird things after we did yeah we were globally remote team and have been since 2011 I think the only other companies of the time that I knew it was a like WordPress automatic was like fully remote yeah 37 signals I think those are the only two that we knew about at least and then I think kind of the third interesting thing about zapier from you know my perspective is you were very early to use LMS like I think you're were like kind of the first company that I saw with real um llm use cases like can you describe what those were and what that experience is like yeah um I think this comes back to the uh Chain of Thought paper that came out in January 2022 like I said actually I my background is um an engineering at College I did like mechanical engineering I did optimization research which ends up being like the exact same math is all this like deting stuff uh I didn't figure this out until 2017 but like as soon as you're on the gr the said podcast actually I yeah exactly as soon as I like figured this out I was like oh okay um uh like I should like I know I know how this works it's like I demystified it a lot and so I started paying more attention to the research side but like zier was growing I had other priorities you know we we had to like you know grow the company introduce new products yada yada and so I really wasn't like that much paying attention um you know I I read the gpd2 paper or the release uh cled with it I read the gbd3 paper gave a whole presentation to the company on it and you know then it's was like okay cool we can do some maybe basic stuff around the margin Cool Tech but that's it and then this then this like January 2022 G Chain of Thought Jason W paper came out and that's what really got me to say oh this might actually be extrem relevant now for what Zapp your customers are trying to do um and I actually went to Wade who's CEO and I said Wade uh I need you to take all like take back all my my half the company uh you need you need to go run product engineering because I need to just go do AI research here at out here and figure out like what is this mean for us for our business for our customers and so for good six 12 months me and Brian CTO just like coded all day long and tried to understand what can this te do what can't do what were the limits and that got us and this is like summer 2022 so we're still four or five months before even chachu kti came out um and we had built graph like we had built like tree of thought prototypes we had built a version of chachu kti internally using this techn like we had pretty much prototyped all the kind of foundational pieces in probably like three or four months and identified that like probably the most obvious place app here could start playing first was this like concept of tool use could we equip LMS that are frozen weights right that don't have the ability to take action in the world world could we equip them with the tools of on zapp's platform all the actions all the search end points that we have and allow them to do more and and that that kind of activated us really early on to start building and delivering AI products and I think that's the reason why we're so early and it also gave me a pretty you know this leads into the later story but it was also the um I think what allowed me to start seeing the limitations of this Paradigm really early as well because you know I I spent I talked to hundreds of zapier customers trying to deploy this like AI technology in the middle of their automations to do stuff and um you know these like we zap has been deploying AI agents now for two years so I've just gotten to hear like what what what do people want from this Tech what and what what does it not work and the number one problem that they all tell me it's consistent across the board is like the promise is there I get what it can do for my business but I just don't trust it enough yet to go hands off and again zap's an automation prodct it's different from chash PT right where it's like you're typing on a keyboard and you get a response you can audit it zaap is running on a server offline you're not watching you're monitoring it and that was the feedback I just don't trust it because the reliability is not high enough in how it's operating yet to not quit a human sort of in the loop and and and this was kind of like this this feedback was so loud and unchanging from gbd like 3 and a half to four to 40 and it was in the same contrast of like all this you know Dogma around scaling hype that was crazy for 20123 into 2024 and just wasn't matching up with my Liv reality and I and I was like okay how how the heck do I explain this um you know I have two sets of facts that like are in congruent and that's when I uh kind of rediscovered franois podcast on Lex back for during Co which is when I think I first listened to him and learned about the arc Benchmark more i' actually like been thinking about a little bit um but really dug in read the on measure of intelligence paper that you published in 2019 and that was kind of my aha moment because I thought that paper did a really good job of articulating the third promise of the technology that we've seen and why it's important and impressive but also where it's fundamental limits on just scaling up pretraining memorization we're going to hit to that was leading to all the the facts that I was seeing from from customer and once I got to that conclusion I was like well clearly AR Benchmark is the number one most important Benchmark in the world more people should know about it and uh going into last summer at least it was a relatively obscure Benchmark at that point and then you you made a prize to for The Benchmark yeah do you wanna do you want to talk about that like that I think the the Z was where where I kind of in this phas is where you where you and I like you made the introduction to to Francois which thank you for doing that I think that's hope been a very helpful thing for the World um I think you got hopefully High leverage out of that introduction here uh the I got you on the podcast so that's great the world the world thanks you Lucas for for doing that um and uh and yeah so I i' been maybe surveying research in the Bay Area at least for a couple maybe like a year or six months of that point on like hey I think this is the most important Benchmark have you ever heard of it and the awareness rate on Arc was relatively low it was like 10 20 20% of people I met had had heard about it most of people who thought they had heard about it actually heard about the old bad version from like the Allen Institute that had been like long beaten by language models and it was just like this you know relatively obscure thing um you know the it had a franois and this other um sort of Swifts lab like lab 42 been running the small version of a contest for several years going to that point so there was some evidence that it was like a robust Benchmark it wasn't like you know completely obscure but certainly in the AI industry it was a under uh you know the the rareness is quite low and and I was like well this is direct concrete evidence it's probably the only major concrete public evidence we have that like there are fundamental limits to prescaling every other Benchmark in the world was like saturating out faster and faster except for Arc and I was like awareness is clearly the problem and so after your introduction I flew up to Seattle and I got lunch with them and I was like you know I pitched up on my ideas of like how to be dark I had some ideas and um it was a fun shout but I also had some like pretty critical you know questions of like why don't why do you think awareness is so low why aren't you you know why aren't you working on it more and he had really good answers for for all so the key questions I had and you know I walked out of that I had one question at the very end of my notes when I was flying up that I put together which is like you know pitch pitch Arc prize and I was like and and I was like okay I I think that I think that it is true that this is just like the reason awareness is low is because it's legitimately hard you know every Frontier lab has given it a try um and I that increased my confidence that was a really important Benchmark that we should grow awareness around so I was like well one way I know we could probably do that is with a prize I I just seen Nat mat Freeman and uh Dan run the vious challenge the previous year which was super successful growing awareness around this like kind of obscure problem and growing the status growing the interest in it to get people to kind of shift gears and work on it and so it's like I bet we could do something similar and that's where ultimately Arc priz came from and so what happened when you launched the Arc priz was it successful in in getting engagement with the like new engagement with the well um I think going into June 2024 again like 10% of AI researchers had heard about Ark I think coming out of 2024 the year like as of December 31st everyone in Tech has probably heard about Arc so like I think we solved it honestly my my my true response is like I have been continually surprised at how much energy there has been around the Benchmark you know we like I'll give you a concrete example of this we um we were going into at the end of the contest was in like early November and um you know we had a a bunch of teams on the leaderboard one of their you know requirements for um winning the cash prize was that you open source your progress this is an idea of trying to rebaseline the progress in the community uh each year and the number one team you know who was um you know it was kind of the runaway winner uh they they had been on the top of the leaderboard all summer long um you had this like 55% score or something like this and uh you know they they emailed us the week before like four five days before the contester I was like hey guys we're not sure we want to open source our our solution and I was like oh man shoot is the like you know is this is is this going to work you know did we get something fundamentally wrong about like how to structure this contest to like help make progress towards a go faster and in the next 72 hours after that call happened at the close of the contest there was like three other two other teams that shot up the leaderboard from like I don't know 10th place up to Second Place the there were the number two team actually was like right at me and neck with the number one team there was like three different papers that got dropped within 24 hours of the contest that just timed their Arc research papers to drop kind of like at the same time to like time it and enter the paper contest and it was just this phenomenal amount of like energy right at the end of the contest that it was kind of just hidden from us we just didn't see see it all and uh I think that happened again when we when open a eyes1 model came out there was just this incredible outpouring of demand for us to test 01 on Arc that I didn't expect I mean we had like thousands of people on Twitter like begging us to go test this thing and so we did like and it was important I'm GL we did it but it was just like there's been these moments of um surprise I guess for me in terms of its relevancy and I think how much like awareness we've been able to gr around it what kind of insights do you think have come out of um wrestling with the price or with the challenge in terms of like structuring contest like this no no actually I mean in terms of um in AI like you know like what what approaches have worked have we learned about how to build intelligence systems so the classic way that people have been trying to beat Arc for four years was with program synthesis pure program synthesis uh the idea is to you know you build a domain specific language think about as like little python functions python Transformations and you build this DSL typically by human like looking at the puzzles and trying to make sort of guesses you about what the Transformations could be and then you have a Brute Force search effectively over the space of all possible combinations of those transforms to look for ones that match your input and output and then you apply them on the test this kind of the classic way you tried people tried to beat it up till you know this year basically um and it doesn't really work well it's just very slow it's very inefficient um uh but like and it's very Brut right because it's like all the sort of you know generalities built into the DSL that the human is sort of going after and Arch 2024 there was a couple brand new approaches that were really interesting to to see that I think the sort of conscious popularized you know I think the the first major one was um early on about using I guess like um it's like a induction based approach where you're trying to generate lots and lots of like python programs using language models and then searching over and like kind of hinting and and sort of informing the language model and how they generate a Python program uh based on sort of the input from the puzzle in order to kind of guide the language model program Generation Um and this is like Ryan greenblat thing he got a really really early score like around 40% or so using a technique like this it was very inefficient like you you to jate hundreds of millions of python programs to do it but it it kind of like showed some promise of this like program induction style method how do you like pick among like you gener those per but how do you pick which one looks promising you run them but this is It's RL right it's like symbolically verified when you gener program you can run the program but then how do you evaluate if it's is it easier to evaluate if an answer is right than yeah J the data set has like has the answer you know and so it's like and this is like true of all um you know math coding this is where1 R1 03 all really dominate right is in these sort of easy to verify domains where you have an answer and you can check it quickly if a computer can check the answer quickly and with strong you know with exacting correctness then this this these types of things will will work um and the other big one was test time training this is the other really big kind of Novel approach that we saw come about where um you know both these basically are trying to adapt to novelty it's like what what they're trying to get out uh and the way test time training kind of works is the Arc uh data set has a public data set and there's a private data set and this is the one the cago contest the actual money prize is attached to private data set no one has seen very few humans are ever seen in the world and you're not allowed to see it when your test gets in order to have strong guarantees around um ability to adapt your you know we try to reduce the chance of like cheating or or fitting on the private data set and so what people figured out is that they can take the private data set inside kle and use that data as a starting spot to generate lots and lots of uh similar data using data augmentation they might like change the colors mirror the grid things that don't change the semantic rule but things that generate lots of like nearby permutations they then fine-tune a model using these like you know several thousand tens of thousands of like you know uh locally trained things and then they influence it and that actually was working I think that's what got one of the top 50% uh scores was this parad of of test sign training and I do think that like you've kind of got two really broad points of evidence now even even with re beating Arc V1 two broad sets of ways that you can that we know about how to use language models to adapt to novelty one is coot search which is which is like what o1 Pro and O3 do they're doing lots of sampling lots of search in their per cot step and then you've got this test TR parad test test time training Paradigm where you want to take the the you know situation and try to um you know create data augmentation around that in order to feed that back into the manifold and do inference on it this is a form of knowledge recomposition I guess is a way to think about it and uh Arc shows that both these approaches are are are pretty promising in terms of getting computers to um not just you know strictly memorize what they've been working on for which TR on before do you think if like Arc was broader and not just sort of in this domain of sort of like pixels and changing colors if that would kind of break that approach like it seems like you have sort of contained the domain of art by just the the format of it like I remember um I remember OB way you oh God I just like I remember reading Douglas Hofer book as a kid I think where he like makes these sequences of numbers and you just try to like guess what the next number would be in the sequence like that sort of seems like a variant of like an ark like reasoning challenge but in a different structure yeah this is something that's underappreciated about Arc I think or a miscon like a common misconception about Arc is that it is a visual Benchmark um you know it's I get why this this conception exists cuz like we render it visually for humans to take see the intuition is like ah you know our intelligence systems aren't good at ARC because they just aren't like good at dealing with visual domains yet um Arc is should more be thought of as a program synthesis Benchmark than it is thought of as a visual Benchmark and the intuition here is that like classic program SYM is exactly what you just said it is given a sequence of integers in in a sequence out figure out what's the rule how do you map the 1D line of numbers into another sequence of 1D aray of numbers Arc extends that into 2D for the first data set it's just like it's a matrix instead of an array and but it's still at its art a uh it's a program synthesis like challenge of like okay given given a matrix of numbers now instead of a a vector of numbers what's the transformation role the exact same problem statement Still Still surrounds um and now ti ti I think here kind of made curiosity was like isn't this kind of like domain like constrained um could could you get into like non-formal domains with this kind of stuff um I I think this is where like pure program synthesis is not going to be able to do that uh you are going to have to in order to like kind of solve Arc the hard way and build a system that has a lot of domain generality you're going to need to merge deep learning and program synthesis together into the system alwi PPS is just going to be sort of too I think fundamentally brutal uh in order to like represent everything there you're going to need some degree of being able to like create model descriptions and you know um be be a bit fuzzier on the edges around how to sort of capture that model um but but ultimately yeah I think you know Arcus is today at least to better articulated at least be one as a as a program synthesis Benchmark um that we haven't been progress on okay so that actually so that that makes me think of a question which is is the 2D nature of Arc like essential to it at all I think it's an important design principle because it's trying to make us I think one of the magic this is all credit to France well one of the beautiful things about Ark is its ability to be to to capture your curiosity as Kema right you look at the puzzles and I I've given them luck to a lot of people my friends and family and everyone you look at the puzzles and based on all the hype you hear about Ai and all you know coming last year um and all of the sort of even individual intuition of working with these systems you look at them you're like you take the puzzle you're like oh okay that was re and then you're told like yeah I can't do that yet you're like wait what like are you are you sure like what if I just what if I just like pasted it like I'll just take a screenshot and throw are you really really totally toally it just like invites this curiosity moment of like what's going on here and that that I think is it's like I think it's really standout thing and why we render The Benchmark visually is to like make a strong not just a claim about something that like is intellectually interesting about you know capability we don't have yet but its goal is to inspire people to work on it you know benchmarks aren't useful if no one actually cares about them and and I think Arc has done a really good job France did a really good job from the design standpoint of making it something that captures your imagination makes you ask why and it pulls you down in the funnel of like all right let me just try I some ideas let me just go try it um and and it's it's goal is to inspire folks right like this is this is the whole point of launching AR cries was you know we launched it to raise awareness on this important unbeaten Benchmark and ra awareness of this like definition of AGI this design principle we have around that Benchmark and to inspire more AI researchers to go try new ideas you know my sort of macro philosophy at this point in my life is basically AGI is the most important technology in the history of humanity we should be doing everything possible anybody who has any unique idea of how to go beat this thing should be try to create AI should be trying to do it myself included um and this is like I was I I got got really frustrated around how much when I when I met researchers talk with Venture investors like how much funding energy mind share just going into into this one Paradigm and like even if it's the right one the world deserves like a few counter bets just to make sure to be increase our overall chance that we're going to get there um and and so I stand by that I I think we we want the strongest Global Innovation environment we can get in order to get to AI as quickly as possible so we can live in that future and use to actually accelerate the future uh that like we all want okay so your new organization um is that is that this the idea that you're going to make some counter bits yeah yeah so India FR I uh we launched it a few weeks ago officially announced it um uh France I started to do I'll call it like a you know intelligent science lab basically um and our view is that uh the way to get to AGI that it removes most of the bottlenecks that we currently see even from systems like O3 is a combination of deeping and Par syes we've actually been talking about this for like since we started launching AR prize like we we gave like we went on this big University tour and sort of espoused his Viewpoint say you can go find those talks you're curious to like get the gist of the idea um this is basically the idea we want to the you know deep learning and program synthesis are are two completely different paradigms and and program synthesis by the way program search is what's making O3 work so I think we have very strong evidence now uh that this new this is the new paradigm that is actually unlocking this new set of capabilities and my belief is that I think in retrospect you know we're going to look at this 03 kind of you know beating rv1 in December moment as the sort of starting point of another five to 10 year scaling Journey on program synthesis in a similar way that we look back in 2012 at like you know Alex net beating the image net contest funny enough it was literally contest they running um and and that's kind of viewed as one of the shotgun kickoff moments of of deep learning um and I think we're kind of at that point today where we're looking ahead of the next five to 10 years and you know we what don't we have here like we don't have you know and this is sort of A Sort colorful rhetoric but like we don't have the you know the transformer for program synthesis yet uh like there's there's a lot of technology that has not been invented you even look at the fields here you've got like probably a million deep learning experts now in the world today or at least engineers in the world today you've probably got in comparison like a few hundred folks on the program Sy this side and if this is truly the path to AI we're going to need to grow that field we're right at the starting spot and uh that's that's our basic view is that uh we're going to need to merge these two paradigms in order to get extremely efficient hii technology that doesn't have human bottlenecks in our terms with learning process okay so what is program synthesis the best way I can articulate program synthesis is probably by example um so it's actually in a really old field it's older than deeping is it goes back to you know 70s 80s and 90s and that stuff and classic quum synthesis is dealing with trying to figure out a program that uh Maps a sort of integer sequence of numbers to another integer sequence of numbers this is typically The Benchmark that you've like researchers have like cared a lot there's even this really cool like thing called um the like online uh database of like integer sequences it's like literally researchers have like made th hundreds of thousands of these sequences that you can use for this kind of uh this kind of research and you're given an input sequence and output sequence and your goal as a as a as a engineer is to create a computer program that can automatically figure out what that what that sequence is uh you might be surprised Al yeah this is actually a very hard Challenge and the reason is because um you know depending on the complexity of of the program and how much hidden State there is how many hidden variables there are programs can be quite long or quite complex and the longer the program gets you get into this problem of trying to basically enumerate this is kind of the how people classically try have tried to do it is they try to brute force it they they try to just search over every possible program that could potenti that could potentially exist and they just you know check it they're like let me plug in the input and see if I get the output it's extremely inefficient it's exponential it's scaling it's Ox to the end it's like nuts it just like you're never really going to be able to like make this work in a reasonable amount of time but that's the that's the rough form of the rough form of the problem I'll say um is that you're trying to create programs and I'll map this into O3 because I think like how 01 and 03 work because you can actually use these systems or at least you can in know one you can kind of get a better feel for it you know with these chains of thought right oh I give a question it thinks for a while it builds a big Chain of Thought and then it gives you an answer a way to think about that Chain of Thought is like a program it's a natural language program but it is a program it's got like individual steps and each step is kind of like a transformation of the latent space from you know this the step this the thought before to the step after it um and you're constructing it you're sort of constructing this program and what o1 Pro and3 do is they actually program recombination where they actually search over the space of all possible programs very similar to uh how program classic program synth this where you're trying to like enumerate through options to to sort of find it again the big challenge of program synthesis is if I contrast deeping APS is that program synthesis can um learn out of distribution or can you can find programs that generalized to out of distribution this is in contrast to deep learning which cannot right deep learning is like a paradigm where you have you need to give it a lot of data embed it on a high dimensional manifold and you can make quick approximate judgment calls intuitions for inferencing new data off that manifold but you're they're not going to be exacts there's no guarantees of exactness and you need a lot of data and and you're going to get like in distribution accuracy uh program synthesis you're looking for a program you only need probably a couple examples you don't need a million you don't need 100,000 you need like three in order to like find the rule Contours of a program that does that and once you find the rule and you have the program that's going to work for any input no matter what input you give it um so it requires very little data it it generalizes out of domain but HR explosion is your problem you just can't it's just interaction with the search for all possible programs there or in a one's case search for all possible reasoning chains so how do you so like how do you how do you do this well the Insight is to use the sort of pros and cons for both sides to merge them together you want to use you know the upside of doring which is to make quick approximate sketches is you know to inform a search process in order to make sure the search process is not just brute forced you don't want to bruteforce it that's not how hum work hum don't sit here and think through every you know a thousand python programs to sell an AR puzzle we use our intuition to generate like to do the sort of You Know sketch of a couple possible answers to ass solving puzzle and then we symbolically in our head verify it we run through the steps we say okay is this right is this right is this right and if it's not well we go back to our you know deep learning part of our brain and say like okay give me some more ideas and there's a smooth back and forth between the two two systems um and we think that's sort of the fundamental substrate here that we can we can construct around it's funny know my my co-founder Sean has been there a lot of work on S bench like ke verley you got the highest score there and it's a yeah it's funny he talks a lot about the same stuff you're saying like I think you know he's it's a a very different domain but he's using you know 03 and 01 to generate programs and then run them and then try to figure out like which is the best one I guess the run times are expensive here but um if it's is going to be a big factor I think this is something the field of AI research has not reckoned with fully yet um you know when we launched the O3 news uh like we had to report that on a 2d graph where the x-axis was effectually uh like token cost or like cost per task because you're you're we're getting into this Paradigm now in AI where you can spend more money to get higher accuracy and higher reliability now it's still on a logarithmic curve like so you know it's not like it just feels linearly up here but like you can spend more money to get the better answer um in a lot of Demands and this means that you can't report a single Benchmark number anymore in fact AR we still need to fix this for Arc for next year like we need to like have our leaderboard with like kind of an efficiency dimension in it somehow um because like you can't just say oh well okay that system got 75% on The Benchmark well okay well how long did it take them to get that how much did it cost them to get that uh these are types of questions I think we're going to have to like be able to answer make assertions around in order to inspire and guide research attention to continue to drive efficiency because I think that's like there's a couple human bottleneck remaining in these types of reasoning systems once we get past those efficiency is really going to be the main key thing we have to we have to figure out although it's I mean if you can you know use compute to get better answers I mean compute cost reliably goes down right so the shape of that that curve really matters too doesn't it um bet sure I follow sorry if you can like the slope even in log scale of the trade-off between like cost and performance I think also also really matters like I would love to spend you know more money to get better answers in lots of domains yeah I there was definitely a lot out there one of the major ones that's going to start working this year is Agents um coming back to the zappier anecdote you know the number one blocker for deploying automation with agents right now is reliability trust isn't high enough um this is an underappreciated point that I don't think most people have figured out quite yet is that uh what does increasing adapt what what does the ability to adapt to novelty actually mean in practice like oh sure it's a cute bench Market beat that what it really means in practice is you can more consistently get the right the same answer not even necessar the right answer just more consistently get to and answer from these systems and that now gives humans the ability to steer them and control their behavior more precisely than we had before this is going to raise the reliability bar and I think a lot of use cases where people one of use agents and it was not a cost problem it was just like I they just don't work good enough I'm willing to pay up to human labor rate for this system to work now we'll start having those use cases get unlocked as a result of plugging things like 011 pro3 R1 into uh some of the planning steps for for these agent systems work I guess one of the things that turn in the back of my head as I do this interview with you is we're sort of taking for granted that you know this kind of like reasoning is important and I kind of wonder if you're we're like losing people by showing these sort of toy like problems in the sense of like what does that actually translate to in the real world yeah you kind of said it but I guess do you have an intuition like what like where does like the arc price example I'll show you like fantastic I'll give you a funny story uh which is what kind of led me down a lot of this like AI benchmarking path a couple years ago so when you were first building some of our AI agents at zapier um we had one that I had set up uh you zapper has been a a a longtime strong partner with with open AI uh we've been a part I've been a part of three now like major opena launches been been sort of fun um and uh so we we we' have we both of us use slack we have a shared slack Channel and when we were building some of our early ag ag AI agent prototypes um we uh had built a system where we wanted the AG agent to like uh automatically send a message into slack from some uh like lead management stuff coming in from HubSpot or maybe like our sales team was doing transcriptions and feeding into this process and when we were testing it we said hey like let's have the agent like it's got two main functions he needs to fill in to like do this automation he needs to pick a slack channel to send the customer information to and he needs to send a you know write the message of the body the Flack message and we had the agent guessing both um from the inbound message and we would we our system allowed us to like this is how Za say you can give hints to the agents on how to fill in those two Fields like you could say oh for the for the slack Channel use the testing hashtag testing Channel and this is a plain text description and for the message you know grab the lead first name last name phone number email like had to buy and build a build a lead like you know little widget and put it in yeah that'll be the body of the message and uh when we first turned it on um like we had we had a a slack Channel called hashtag testing um the uh name of the channel we had with openi was called like open ai- like partner Das testing and the agent just like picked one a couple times that partnership channel to like start sending you know like information to and it was like Oh shoot that's not good you know this is like a production system you know it's it's a good it's a it's an important partnership we don't want and like we don't want customer FR being like shared like that immedately turn it off scrubed it fixed this situation but it was my first realization moment that like oh reliability and overrides and control are going to be extremely important things for building trust because like the first time you see that you're like and it's like it's a user who saw that it's like nope turn this thing off 10 I'm like get that thing 10 feet away from me I I can't I can't do with this this is you know it's putting my business in Jeopardy um and it was very real it made us realize early on that in order to start toing AI agents like a year and a half ago when we started we needed to offer users hardcoded control over CH uh constraining guessing so in this new case when you use zaer AI agents um you can allow it to guess if you want to but the default is just choose a channel and that allows you to have some amount of certainty and guarantees around well okay it's not going to go off the rails too much or you can you can say here's the three channels I want you to guess from and it allows you to build in that sort of hard guarantee again all this was just early Insight that like reliability matters a ton it's probably the number one thing that matters for deploying agents that can automate tasks that businesses and users care about and that is the type of thing we will now start to see get reliably solved using 010 and3 you're not going to see this sort of as much stochastic Randomness in doing the wrong thing if you if you like build an Asia and say send it to the testing Channel and it works the first three times you're going to expect it's going to keep working and that's going to be the truth whereas in the past with the sort of very you know stochastic nature of how these LM B pure systems have worked you really couldn't make that same guarantee without like you know some extra guard rails on on top that developers created and so why did you start India as its own organization versus work with open AI if you have this close relationship with them like what why do you feel like that it needed a new a new organization um I think the reality is that if you look at the sort of Frontier of what most of these companies are working on um I don't think they share the view that we do about the importance of program synthesis um I've saw Tom F folks Frontier labs open ey included and even showing them like you got these over3 results now and I think there is a a view that this is still we're still in a deeping paradig this is deeping with a little bit of special search stuff on top but that's not really that important I I do think there are people by the way in these work would that get it but I think the broad view still in Industry today is that like this is you know deep Bing is still scaling and I we fundamentally disagree with that perspective we uh my view is that program synthesis is at least 50% of the equation maybe not for from a compute budget standpoint but from like if you were to measure like where are the ideas in the future highly efficient no likei system it's G to be half of that is going to be coming out of the discipline of like program synthesis in some way and like I said before I think AGI is such an important technology anyone who has like a unique differentiated idea I think should be going trying it um I think it's important for the world like this is why we launch dark prize we want to inspire more people just to like go try new stuff again you know try to get back to the AI industry research model we had in 2018 2019 um where everyone was trying new and different ideas and I do think or prise has helped shift the Overton window from a narrative standpoint I'm starting to see it now I'm very excited uh we're starting to see more fundamental Innovation now coming out of a lot of the like small startups in fact one of the biggest things that surprised me about Arc prise you know I I I sort of expected that we were going to get a lot of individual researchers and maybe some big lab attention to like work on The Benchmark the biggest surprise I probably had coming out was about seven or eight startups came up to me some point throughout the contest or afterwards and and told us that they had changed their like these are like AI companies they had like changed they had pivoted they changed the research rat to go work on Arc and I thought that was a really exciting thing to hear because I was like okay I think it's starting to have the impact that we hoped it would which is to get people to at least Explore More and increase the sort of overall probability that like we we figure this thing out um and and you know I think I think we're we've got exciting long-term Ambitions about what we want to use with the technology that I think Al also differ quite a bit from any of the other sort of major players and companies that exist out there um but purely if you're just looking at the technology of like why did we start India I think it is um the fact that we just had a you know I think we have a differentiated view that I think has a high degree of chance of success uh that increases the sort of probability of getting to AGI quickly for the world um and uh we're going to put our full effort and attention into trying and are you also oriented towards making a product and making money and things like that uh I have I have someing view here um so ask you a quick question like no this is a research lab like we are um like there's no offer for products in the near charm like this is get to AGI by my definition our definition you know create reduce this capap to zero between easy for computers hard easy for humans hard for computers um you shouldn't expect to see us really make products uh ahead of that now we may start using the some of the prototypes of the technology to start trying to advance some of the frontiers of science this is actually one of the reasons I mention besides is building Ag Building AG is step one for us the thing that gets us really excited me really excited is to start leveraging the technology to accelerate the sort of pace of innovation we see at the frontier of a lot of different fields of science um like AGI is going to solve a lot of problems no doubt about it it's already solving problems with Z customers like it's going to like and it's not even AI yet like we're like people are going to use this technology to solve a lot of problems that's great I I'm fully supported that the thing that gets me like more excited about the technology is it it it's sort of like accelerating into this like unknown unknown future um and I I'll make this like kind of illustrative story you know around like the printing press you know back in the 1400s when it was first introduced you know was it 600 years ago now um you know like what was the reaction it's like obviously lots of you know fear and skepticism but also a lot of excitement around sort of this knowledge proliferation of uh you know sharing knowledge globally being able to exchange freely ideas um I think if you went to anyone though and like asked them hey make some predictions about what the year you know 2025 looks like uh you they would you'd probably be pretty hard pressed to get anyone to imagine a future of like Wikipedia and AI that got trained on Wikipedia and like I can talk to computers what the computer like you know we're just so far down the technology like tree from these Genesis moments of like the catalyzed everything and I think that's what really gets me it's it's almost more like an adventure than it is problem solving motivated you know there's going to be really exciting cool things that come in the future of technology that I can't even tell you what they are yet um but I think we're in order to get there faster the main constraint is like we need computers that can work on autonomous ways to do Innovation and that is that is bottleneck on creating AGI um and that's what I'm really excited to sort of help be a part of and help accelerate if we can do you have a point of view on timeline Fria to the definition I shed before like you've gotten rid of all the gaps from uh you know easy for confus har fre ey um one one other thing I think it's actually to that definition that is worth considering is the efficiency um you know I I think we'll probably reach that definition before we reach it at a human efficiency level um would be a guess so let me let me go ahead and just like a little add a little Aster on the say like we're able to sort of you know there's there's no remaining tasks that re a prar for AI and like we're doing it at human level efficiency you know what's do can you put a dollar in human level efficiency is that like uh your salary this is literally something we're debating right now how to measure efficiency and and I don't think the industry knows it Arc is still like Arc priz we're trying to figure this out too you kind of want something that you can contrast between humans and computers and like flops aren't really great you could maybe do dollars CU you could like pay computer to do X you know X work for xll you could pay a human to do X work for X doll time is kind of interesting from a walk clock perspective because you can you can make time faster with computers by paralyzing and that's something they're good at right so honestly I don't know the answer um I probably make the advocation that dollars are probably the best one today based on what I know in order to make sort of comparisons because dollars kind of everything fits into Dollars you know how much you pay a human for lior rate versus how much compute costs dollars will track the price performance of compute getting more efficient as well which is kind of nice um we don't know so's Let's uh let's say you like yeah level human level efficiency we're paying humans the thing we're paying computers to do these like easy tasks that humans spine hard um something like that I'll add that I'll add that sort of Aster on um my expectation right now if I if I just had to make some wild guesses you know we got arv2 we're working on for this year um I expect it probably will be durable for let's call 12 to 18 months that's my best guess today based on how it's doing all the frontier systems we've been testing it on um it's not going to be another five-year Benchmark though uh you know like the V1 was because R V2 is kind of in the same domain it's just like it's raising the bar of difficulty for computers without raising the bar of difficulty for humans and that this should be an interesting capability I think it will still be interesting I think it will still be a good gradient a tool that will Point research inding Direction but the thing I'm really excited about is this V3 that we started designing and kind of prototyping um for for next year and our design goal for V3 is that it would be durable for three years that's that's our that's our hope and goal we'll have to obviously make contact with reality and all that stuff but you know my my sort of anticipation is like we will not have you know easy for humans hard for AI solved at that level of efficiency you know based on today for the next at least three to four years honestly I'll tell you this what one of the hardest things in my making predictions is it's very easy to make predictions around smooth scaling curves it's extremely hard to make predictions around step function changes in capability um because obviously curves you can make you can sort of track out right make make future guesses around uh uh capability just joints like if you were looking at the arc if you were trying to make progress B when is arv1 going to reach 85% from a general purpose system it's like going for five years it went from Z to 4% and then in two months it went from 4% to 85 that is an extremely hard thing to predict because two two things about this one you don't know if the technology exists in the world to do it yet you don't know if the ideas are in the world yet to do it yet um and then if they and then if they are in the world you just don't know if someone hasn't like put together into a system to demonstrate it to you so you have a lot of unknown variables in trying to make guesses about when do when do the step function capability jumps sort of happen I am I'm not a I guess to to make my conquer views I do not believe we're in a pure sort of scaling regime up where you can make a nice smooth curve over these like system sizes and cast a way coin out into the future and say that's we're going to have all this stuff solved will have a job at that point um I I treat a lot more empirically and I I think you know you can make informed guesses about when you think step functions might happen but I think it's in the Public's interest to understand that like this is actually the reality we're still looking for step function capability leaps and we don't know when those are going to show up well awesome I think that's a a good stopping point um for this interview this there anything got through a lot of content a lot of content a lot of wide ranging content thanks so much for listening to this episode of Grant descent please stay tuned for future episodes